# Treemap Comparison Resources
This repository hosts the resources used in the paper **Quantitative Comparison of Time-Dependent Treemaps**, by Eduardo Vernier, Max Sondag, Joao Comba, Bettina Speckmann, Alexandru Telea, and Kevin Verbeek.

The `./Datasets` directory contains the 2720 the dynamic hierarchy datasets used in the benchmark.

`./Treemapping Code` has the Java implementations of Approximate (APP), Hilbert (HIL), Local Moves using zero (LM0) or four (LM4) local moves, Moore (MOO), Ordered with Pivot-by-Middle (PBM), Pivot-by-Size (PBZ), and Pivot-by-Split (PBS), Slice-and-Dice (SND), Spiral (SPI), Split (SPI), Squarified (SQR), and Strip (STR).

`./Metrics and Plots Code` has the Python code that computes the metric results for the treemap layouts and generates the plots seen in the paper.

`./Figures` contains the plots for the 46 representatives datasets in the paper.

## Generating Treemaps
This project contains all the code to generate the treemap layouts for 13 different algorithms, visualize them and classify the datasets. Datasets can be classified using `DatasetClassifier.DataSetClassifier.java` as the main class. A folder can be specified here from where to read the data from as well as where to output the classification.

Layouts can be generated by running `UserControl.Simulator.java`. This method can be be called from the command line. An example run is:
`-width 1000 -height 1000 -technique moore -inputfolder D:/datasets/ -outputfolder D:/output/ -baseline true`

In case -baseline is set to true, baselines will be generated for each algorithm as well.
In the function `getTreeMapGenerators` one can specify for which algorithms to run the simulation and generate the output.

If one want to generate baselines for an algorithm not implemented in this codebase, they can use the class `statistics.Baseline.BaseLineGenerator`.
In the main method one can specify where their folder with layouts and dataset is contained, and where to output the generated baselines
In case one want to visualize the datasets using a certain algorithm, `UserControl.Visualiser.Visualizer.java` should be chosen as the main class. One can add additional datasets to be selected in `GUI.java`.

## Generating the figures
To generate the figures it is first necessary to pre-compute the quality metrics.
From the `./Metrics and Plots Code/` directory, run the command `python3 Main.py cache-metrics <dataset_id>`, where dataset_id is the name of the folder that the real layouts are stored, e.g. 'exo' or 'Hystrix', we compute the Aspect Ratio, Corner Travel (real and baseline), and Relative Position Change (real and baseline) metrics cell-wise for all revisions and techniques.

Following the order of the paper, to generate a real vs. baseline KDE scatter plot for Corner Travel and Relative Position Change for a given dataset, run `python3 Main.py kde-ct <dataset_id>` and `python3 Main.py kde-rpc <dataset_id>`.

To generate the time boxplots as seen in Figure 7, run `python3 Main.py boxplots <dataset_id>`. Results for the 4 measurements (unweighted aspect ratio, weighted aspect ratio, diff corner travel, and diff relative position change) will be generated.

To generate Figures 8 (Matrix) and 9 (Star-glyph scatterplot), run `python3 Main.py matrix <dataset_id list>` and `python3 Main.py scatter <dataset_id list>`, where dataset_ids are separated by a single white space, e.g., `python3 Main.py matrix gh-keras-m tmbd-yearly-count-genres-children MoviesHC9Y1W`. The filtered version are generated in the `Notebooks/FilteredStarPlot-newcenters.ipynb` file.

The Rank Matrix (Fig 10) is generated nunnig the `Notebooks/RankMatrix.ipynb` file.

## Dataset extraction
#### GitHub

The dataset selection (for those named `gh-*`) was done through the scrapping of the first 10 pages of [gitmostwanted.com](http://gitmostwanted.com/), which is a website that lists popular GitHub repositories.

For the selected URLs (list can be found [here](https://github.com/EduardoVernier/dataset-generator/blob/master/GitHubMostWanted/repos.txt)), we run a python script that clones revisions of a repository with a given periodicity. For this batch, we used monthly extractions (-m), but the script takes a flag as argument that selects if it should clone yearly (-y), daily (-d), or all revisions (-a).

For each cloned revision, the script invokes the [CLOC tool](https://github.com/AlDanial/cloc) to list and count the number of lines of code in each source file. This is a faster free alternative to Understand.

Datasets are named as `gh-<name_of_repository>-<periodicity>`.

Ex.: _gh-svgo-m_ for the github.com/svg/svgo repository with last commit of month extraction (-m).

The scripts and notebooks used for scrapping, metric collection and file generation can be found [here](https://github.com/EduardoVernier/dataset-generator/tree/master/GitHubMostWanted).

The datasets that are named `GitHub*` where borrowed from previous works ([[1]](https://github.com/sibgrapi18/treemaps) and [[2]](https://github.com/vissoft18/treemaps)) that evaluated dynamic treemaps.


#### WorldBank

The WorldBank Group offers an open database with hundreds of indicators of global development. Their measurements can be downloaded as a large [csv file](http://databank.worldbank.org/data/download/WDI_csv.zip).

Based on that, each indicator that has a minimum number of observations is turned into a dataset for our application. Each row in the original data represents one _Region/Country_ entry and the columns give the indicator value for that entry in a given year. There is one column for each year since the first time the indicator was measured.

Datasets are named `wb-<indicator_id>`, where the _indicator_id_ is a unique code that maps to one global indicator.

For example: _wb-TX.VAL.MMTL.ZS.UN_ corresponds to "Ores and metals exports (% of merchandise exports)" and _wb-EN.URB.MCTY.TL.ZS_ corresponds to "Population in urban agglomerations of more than 1 million (% of total population)".

**The mapping of indicator ids to dataset descriptions can be found [here](https://github.com/EduardoVernier/dataset-generator/blob/master/WorldBank/id_indicator_map.csv)**.

Addtional information about datasets can be found [here](https://github.com/EduardoVernier/dataset-generator/blob/master/WorldBank/wb-series.csv) with descriptions, information about periodicity, aggregation method, limitations and exceptions, statistical concept and methodology, source, license type, etc.

#### TMDB

The raw dataset contains over 20 million reviews about 27,278 movies.
Each user review of a movie has a rating (value from 0 to 5) and a timestamp of when it was posted. The first reviews date to January 1995 and the last to March 2015.
Each movie has an id, year of release and a list of genres it belongs to (sorted alphabetically).
To extract 100+ datasets from this source I defined 4 levels of freedom (hierarchy, cell weight, time aggregation, filters). In bold are the keys that are used to identify the datasets.

* Hierarchy
  * Using genre information. 0 to 7 levels (some movies don't have this info) **[genre]** - Ex.:_Adventure/Animation/Children/Comedy/ToyStory_
  * Using year information. Always two levels. **[year]** - Ex.:_1995/ToyStory_
* Cell weight
  * Number of reviews in a given period.  **[count]**
  * Average rating in a given period.  **[average]**
  * Review standard deviation in a given period. **[std]**
* Time aggregation by review timestamp
  * Aggregate monthly (~240 months or revisions).   **[monthly]**
  * Aggregate yearly (~20 years or revisions).   **[yearly]**
* Filters
  * Only action movies.  **[action]**
  * Only children movies.  **[children]**
  * Only documentaries.  **[documentary]**
  * Only movies from 60s, 70s and 80's.  **[60sto80s]**
  * Only movies from 90s.  **[90s]**
  * Only movies from 2000 onwards. **[00stonow]**
  * Only movies with 4 or more genres.  **[4plusngeres]**
  * Only movies without genre info.  **[nogenre]**
  * 2000 randomly selected movies.  **[2krand]**

This gives us 2 * 3 * 2 * 9 = 108 datasets. Datasets are named `tmdb-<periodicity>-<weight_value>-<hierarchy_type>-<filter>`.

For example:
_tmbd-monthly-mean-genres-documentaries_ gives the average monthly rating for documentaries using the genre hierarchy and _tmbd-yearly-count-release-90s_ counts the number of reviews 90s titles received during each year using the hierarchy given by Year/Title.

The code that generated the datasets is available [here](https://github.com/EduardoVernier/dataset-generator/tree/master/TMDB).

#### Movielens
The MovieLens database. This database contains 45,000 movies, 750,000 keywords attached to these movies, and 26 million time-stamped 0 to 5 star ratings over roughly 22 years. The naming convention for these files is as follows:

`Movies<hierachical><cumulative><collection_period><aggregation_period>`

If the name contains the H of _\<hierarchical\>_ we have a fixed 4 level hierarchy.

We first partitioned on the genres Crime, Adventure and Drama;
second on the movie release date (before vs after 2010); third on the tags Ford, Pitt, Depp, Hanks, Stewart, Cooper, Grant, and Flynn; fourth on whether the movie title contains the word Act, War, Love, Time, Spirit, Night, or any other word; fifth on whether tags contain Friend, Enemy or neither/both; and finally on whether tags contain Past, Future or neither/both. This results in a very deep hierarchy with a large imbalance in the tree depths.

If the name does not contains the H of _\<hierarchical\>_ it is a dataset consisting of only a single level. In this case we only considered movies with genres Action and Adventure to trim down the sheer amount of movies.

If the name contains the C of _\<cumulative\>_ it means we consider all ratings from the start of the collection period until now. Otherwise we only consider the ratings in the current aggregation period.

The _\<collection_period\>_ indicates over how long a period we are collecting the data. The _\<aggregation_period\>_ indicates how much time passes between two samples. _Y_ indicates a year, _M_ indicates a month, _D_ indicates a day, _H_ indicates an hour.

A few examples are: _Movies15M1D, Movies3Y3M, MoviesC4Y90H, MoviesH22Y7M, MoviesHC10Y2M._
